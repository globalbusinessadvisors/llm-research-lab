//! Markdown generation for benchmark results
//!
//! This module provides utilities for generating human-readable markdown
//! reports from benchmark results.

use std::collections::HashMap;
use std::fs::File;
use std::io::{BufWriter, Write};
use std::path::Path;

use chrono::Utc;

use crate::result::BenchmarkResult;

/// Generate a markdown summary from benchmark results
pub struct MarkdownGenerator {
    title: String,
    description: Option<String>,
}

impl Default for MarkdownGenerator {
    fn default() -> Self {
        Self::new("Benchmark Results")
    }
}

impl MarkdownGenerator {
    /// Create a new MarkdownGenerator with a title
    pub fn new(title: impl Into<String>) -> Self {
        Self {
            title: title.into(),
            description: None,
        }
    }

    /// Set the description for the report
    pub fn with_description(mut self, description: impl Into<String>) -> Self {
        self.description = Some(description.into());
        self
    }

    /// Generate markdown content from benchmark results
    pub fn generate(&self, results: &[BenchmarkResult]) -> String {
        let mut md = String::new();

        // Header
        md.push_str(&format!("# {}\n\n", self.title));

        if let Some(desc) = &self.description {
            md.push_str(&format!("{}\n\n", desc));
        }

        // Metadata
        md.push_str(&format!(
            "**Generated:** {}\n\n",
            Utc::now().format("%Y-%m-%d %H:%M:%S UTC")
        ));
        md.push_str(&format!("**Total Benchmarks:** {}\n\n", results.len()));

        // Summary statistics
        if !results.is_empty() {
            md.push_str("## Summary\n\n");
            md.push_str(&self.generate_summary_table(results));
            md.push('\n');
        }

        // Detailed results
        md.push_str("## Detailed Results\n\n");

        if results.is_empty() {
            md.push_str("_No benchmark results available._\n");
        } else {
            for result in results {
                md.push_str(&self.format_result(result));
                md.push('\n');
            }
        }

        // Footer
        md.push_str("---\n\n");
        md.push_str("_Generated by LLM Research Lab Canonical Benchmark System_\n");

        md
    }

    /// Generate a summary table of results
    fn generate_summary_table(&self, results: &[BenchmarkResult]) -> String {
        let mut table = String::new();

        table.push_str("| Target | Duration (ms) | Status | Timestamp |\n");
        table.push_str("|--------|---------------|--------|------------|\n");

        for result in results {
            let duration = result
                .duration_ms()
                .map(|d| format!("{:.2}", d))
                .unwrap_or_else(|| "-".to_string());

            let status = if result.is_success() {
                "Pass"
            } else {
                "Fail"
            };

            table.push_str(&format!(
                "| {} | {} | {} | {} |\n",
                result.target_id,
                duration,
                status,
                result.timestamp.format("%Y-%m-%d %H:%M:%S")
            ));
        }

        table
    }

    /// Format a single result as markdown
    fn format_result(&self, result: &BenchmarkResult) -> String {
        let mut md = String::new();

        md.push_str(&format!("### {}\n\n", result.target_id));

        // Status badge
        if result.is_success() {
            md.push_str("**Status:** Pass\n\n");
        } else {
            md.push_str("**Status:** Fail\n\n");
            if let Some(error) = result.error() {
                md.push_str(&format!("**Error:** {}\n\n", error));
            }
        }

        // Timestamp
        md.push_str(&format!(
            "**Timestamp:** {}\n\n",
            result.timestamp.format("%Y-%m-%d %H:%M:%S UTC")
        ));

        // Metrics
        md.push_str("**Metrics:**\n\n");
        md.push_str("```json\n");
        md.push_str(
            &serde_json::to_string_pretty(&result.metrics).unwrap_or_else(|_| "{}".to_string()),
        );
        md.push_str("\n```\n");

        md
    }

    /// Write markdown to a file
    pub fn write_to_file(&self, results: &[BenchmarkResult], path: impl AsRef<Path>) -> std::io::Result<()> {
        let content = self.generate(results);
        let file = File::create(path)?;
        let mut writer = BufWriter::new(file);
        writer.write_all(content.as_bytes())?;
        writer.flush()?;
        Ok(())
    }

    /// Generate a comparison report between two result sets
    pub fn generate_comparison(
        &self,
        baseline: &[BenchmarkResult],
        current: &[BenchmarkResult],
    ) -> String {
        let mut md = String::new();

        md.push_str(&format!("# {} - Comparison Report\n\n", self.title));

        // Build lookup maps
        let baseline_map: HashMap<_, _> = baseline.iter().map(|r| (&r.target_id, r)).collect();
        let current_map: HashMap<_, _> = current.iter().map(|r| (&r.target_id, r)).collect();

        // Comparison table
        md.push_str("## Performance Comparison\n\n");
        md.push_str("| Target | Baseline (ms) | Current (ms) | Change |\n");
        md.push_str("|--------|---------------|--------------|--------|\n");

        for (target_id, current_result) in &current_map {
            let baseline_duration = baseline_map
                .get(target_id)
                .and_then(|r| r.duration_ms());
            let current_duration = current_result.duration_ms();

            let change = match (baseline_duration, current_duration) {
                (Some(b), Some(c)) => {
                    let pct = ((c - b) / b) * 100.0;
                    if pct > 0.0 {
                        format!("+{:.1}%", pct)
                    } else {
                        format!("{:.1}%", pct)
                    }
                }
                _ => "-".to_string(),
            };

            md.push_str(&format!(
                "| {} | {} | {} | {} |\n",
                target_id,
                baseline_duration.map(|d| format!("{:.2}", d)).unwrap_or_else(|| "-".to_string()),
                current_duration.map(|d| format!("{:.2}", d)).unwrap_or_else(|| "-".to_string()),
                change
            ));
        }

        md.push_str("\n---\n\n");
        md.push_str("_Generated by LLM Research Lab Canonical Benchmark System_\n");

        md
    }
}

/// Create the summary.md file with current results
pub fn create_summary(results: &[BenchmarkResult], output_dir: impl AsRef<Path>) -> std::io::Result<()> {
    let generator = MarkdownGenerator::new("LLM Research Lab Benchmark Results")
        .with_description("Canonical benchmark results for LLM Research Lab operations.");

    let path = output_dir.as_ref().join("summary.md");
    generator.write_to_file(results, path)
}

#[cfg(test)]
mod tests {
    use super::*;
    use serde_json::json;

    #[test]
    fn test_markdown_generation() {
        let generator = MarkdownGenerator::new("Test Report");
        let results = vec![
            BenchmarkResult::new("test-1", json!({"duration_ms": 100.0, "success": true})),
            BenchmarkResult::new("test-2", json!({"duration_ms": 200.0, "success": false, "error": "timeout"})),
        ];

        let md = generator.generate(&results);

        assert!(md.contains("# Test Report"));
        assert!(md.contains("test-1"));
        assert!(md.contains("test-2"));
        assert!(md.contains("Pass"));
        assert!(md.contains("Fail"));
    }

    #[test]
    fn test_comparison_report() {
        let generator = MarkdownGenerator::new("Comparison");
        let baseline = vec![
            BenchmarkResult::new("target", json!({"duration_ms": 100.0})),
        ];
        let current = vec![
            BenchmarkResult::new("target", json!({"duration_ms": 90.0})),
        ];

        let md = generator.generate_comparison(&baseline, &current);

        assert!(md.contains("Comparison Report"));
        assert!(md.contains("-10.0%"));
    }
}
